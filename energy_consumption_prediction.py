# -*- coding: utf-8 -*-
"""Energy Consumption Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HaClHabrv548nS0rZAq36LR30ICp9n96
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import os
import random

""" Phase 1: Data Cleaning and Validation"""

def clean_energy_data(file_path):

    try:
        df = pd.read_csv(file_path)
        print("Data loaded successfully.")
    except FileNotFoundError:
        print(f"Error: The file '{file_path}' was not found.")
        print("Please make sure 'AEP_hourly.csv' is in the same directory as this script.")
        return None

    print("First 5 rows of the raw data:")
    print(df.head())
    print("\nShape of the raw data:", df.shape)
    print("\nData types of raw data:")
    print(df.info())

    df['Datetime'] = pd.to_datetime(df['Datetime'])  # Convert 'Datetime' column to datetime objects
    df.set_index('Datetime', inplace=True) # Set the 'Datetime' column as the index of the DataFrame
    df.sort_index(inplace=True)
    df = df.rename(columns={'AEP_MW': 'Load_MW'})
    print(df.info())

    missing_values_count = df.isnull().sum()

    if missing_values_count.sum() == 0:
        print("Result: No missing values found. The dataset is complete.")
    else:
        print("Warning: Missing values detected!")
        print(missing_values_count[missing_values_count > 0])

        # For time-series data, linear interpolation based on time is a robust approach for filling small gaps. It estimates a value based on the points before and after.
        df.interpolate(method='time', inplace=True)

        # An alternative, simpler method is forward fill ('ffill'), which carries the last known value forward.
        # Example: df.fillna(method='ffill', inplace=True)

        if df.isnull().sum().sum() == 0:
            print(f"Successfully imputed {missing_values_count.sum()} missing values.")
        else:
            print("Warning: Some missing values still remain after imputation.")

    print(df['Load_MW'].describe().round(2))
    return df

"""Phase 2: Exploratory Data Analysis"""

def perform_eda(df):
    df_eda = df.copy()
    df_eda['hour'] = df_eda.index.hour
    df_eda['dayofweek_name'] = df_eda.index.day_name()
    df_eda['month'] = df_eda.index.month

    # Generating plot for overall energy consumption
    daily_df = df_eda['Load_MW'].resample('D').mean()
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(14, 7))
    ax.plot(daily_df.index, daily_df.values, color='dodgerblue', linewidth=1)
    ax.set_title('Average Daily Energy Consumption (2004-2018)', fontsize=16)
    ax.set_xlabel('Date', fontsize=12)
    ax.set_ylabel('Average Daily Load (MW)', fontsize=12)
    plt.tight_layout()
    plt.show()

    fig, axes = plt.subplots(3, 1, figsize=(14, 7), sharex=False)

    # Plot 1: Monthly Pattern
    sns.boxplot(data=df_eda, x='month', y='Load_MW', ax=axes[0])
    axes[0].set_title('Monthly Energy Consumption Pattern', fontsize=14)
    axes[0].set_xlabel('Month')
    axes[0].set_ylabel('Load (MW)')

    # Plot 2: Day of Week Pattern
    sns.boxplot(data=df_eda, x='dayofweek_name', y='Load_MW', ax=axes[1], order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])
    axes[1].set_title('Day of Week Energy Consumption Pattern', fontsize=14)
    axes[1].set_xlabel('Day of the Week')
    axes[1].set_ylabel('Load (MW)')

    # Plot 3: Hourly Pattern
    sns.boxplot(data=df_eda, x='hour', y='Load_MW', ax=axes[2])
    axes[2].set_title('Hourly Energy Consumption Pattern (Circadian Rhythm)', fontsize=14)
    axes[2].set_xlabel('Hour of the Day')
    axes[2].set_ylabel('Load (MW)')

    plt.tight_layout()
    plt.show()

    # Generating heatmap for hourly vs. daily patterns
    pivot_table = df_eda.pivot_table(values='Load_MW', index='hour', columns='dayofweek_name', aggfunc='mean')
    pivot_table = pivot_table[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]

    plt.figure(figsize=(14, 7))
    sns.heatmap(pivot_table, cmap='coolwarm', annot=False, fmt=".0f")
    plt.title('Average Energy Load (MW) by Hour and Day of Week', fontsize=16)
    plt.xlabel('Day of the Week', fontsize=12)
    plt.ylabel('Hour of the Day', fontsize=12)
    plt.tight_layout()
    plt.show()

    # Time Series Decomposition ---
    decomposition_slice = df_eda['Load_MW']['2010-01-01':'2011-12-31']

    result = seasonal_decompose(decomposition_slice, model='additive', period=168)

    fig = result.plot()
    fig.set_size_inches(14, 7)
    fig.suptitle('Time Series Decomposition (Weekly Seasonality)', fontsize=18, y=1.01)
    plt.tight_layout()
    plt.show()

"""Phase 3: Feature Engineering"""

def feature_engineering(df):
    # Time-Based Features ---
    df['hour'] = df.index.hour
    df['dayofweek'] = df.index.dayofweek
    df['quarter'] = df.index.quarter
    df['month'] = df.index.month
    df['year'] = df.index.year
    df['dayofyear'] = df.index.dayofyear
    df['lag_1hr'] = df['Load_MW'].shift(1)
    df['lag_24hr'] = df['Load_MW'].shift(24)
    df['lag_1week'] = df['Load_MW'].shift(24 * 7)
    df['rolling_mean_24hr'] = df['Load_MW'].shift(1).rolling(window=24).mean()
    df['rolling_std_24hr'] = df['Load_MW'].shift(1).rolling(window=24).std()
    df.dropna(inplace=True)
    return df

    # Lag Features
    df['lag_1hr'] = df['Load_MW'].shift(1)      # Load from the previous hour
    df['lag_24hr'] = df['Load_MW'].shift(24)    # Load from the same hour on the previous day
    df['lag_1week'] = df['Load_MW'].shift(24 * 7) # Load from the same hour on the same day of the previous week

    # Rolling Window Features
    df['rolling_mean_24hr'] = df['Load_MW'].shift(1).rolling(window=24).mean()
    df['rolling_std_24hr'] = df['Load_MW'].shift(1).rolling(window=24).std()

    # Handle Missing Values from Feature Creation
    original_rows = len(df)
    df.dropna(inplace=True)
    new_rows = len(df)
    print(f"Dropped {original_rows - new_rows} rows with NaN values.")
    return df

"""Phase 4: Model Evaluation"""

def modeling_evaluation(df):

    # min_year = df.index.year.min()
    # max_year = df.index.year.max()
    # possible_test_years = range(min_year + 1, max_year)

    # test_year = random.choice(possible_test_years)
    # print(f"Randomly selected year {test_year} as the test set.")

    test_df = df.loc[df.index >= "2017-01-01"]
    train_df = df.loc[df.index < "2017-01-01"]

    print(f"Training data covers: {train_df.index.min()} to {train_df.index.max()}")
    print(f"Testing data covers:  {test_df.index.min()} to {test_df.index.max()}")


    # Features (X) and Target (y)
    FEATURES = ['hour', 'dayofweek', 'quarter', 'month', 'year', 'dayofyear',
                'lag_1hr', 'lag_24hr', 'lag_1week', 'rolling_mean_24hr', 'rolling_std_24hr']
    TARGET = 'Load_MW'

    X_train, y_train = train_df[FEATURES], train_df[TARGET]
    X_test, y_test = test_df[FEATURES], test_df[TARGET]

    model = RandomForestRegressor(n_estimators=100,
                                  n_jobs=-1,        # Use all available CPU cores
                                  random_state=42,
                                  max_depth=15,       # Limit tree depth to prevent overfitting
                                  min_samples_split=5) # Require at least 5 samples to split a node

    model.fit(X_train, y_train)

    hybrid_preds = model.predict(X_test)

    # Baseline Model: Seasonal Naive predictions
    baseline_preds = test_df['lag_1week']

    baseline_mae = mean_absolute_error(y_test, baseline_preds)
    hybrid_mae = mean_absolute_error(y_test, hybrid_preds)

    baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_preds))
    hybrid_rmse = np.sqrt(mean_squared_error(y_test, hybrid_preds))

    print("\n--- Model Performance Comparison ---")
    results = {
        "Model": ["Baseline (Seasonal Naive)", "Hybrid Model (RF)"],
        "MAE (Megawatts)": [baseline_mae, hybrid_mae],
        "RMSE (Megawatts)": [baseline_rmse, hybrid_rmse]
    }
    results_df = pd.DataFrame(results)
    print(results_df.round(2))

    if baseline_mae > 0:
      improvement = ((baseline_mae - hybrid_mae) / baseline_mae) * 100
      print(f"\n The hybrid model shows a {improvement:.2f}% improvement in accuracy (MAE) over the baseline.")


    # Visualizing Model Predictions vs. Actuals (First Week of Test Data)
    plot_slice = y_test.iloc[:24*7]

    plt.figure(figsize=(14, 7))
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.plot(plot_slice.index, plot_slice.values, label='Actual Load', color='blue', linewidth=2.5)
    plt.plot(plot_slice.index, hybrid_preds[:len(plot_slice)], label='Hybrid Model Prediction', color='red', linestyle='--')
    plt.title('Hybrid Model Predictions vs. Actual Load (First Week of Test Data)', fontsize=16)
    plt.ylabel('Energy Load (MW)', fontsize=12)
    plt.legend(fontsize=12)
    plt.show()

if __name__ == "__main__":
    file_name = '/content/AEP_hourly.csv'
    cleaned_df = clean_energy_data(file_name)

    if cleaned_df is not None:
      print(cleaned_df.head())

      perform_eda(cleaned_df)

      featured_df = feature_engineering(cleaned_df)
      print(featured_df.head())

      print(featured_df.columns)

      modeling_evaluation(featured_df)

